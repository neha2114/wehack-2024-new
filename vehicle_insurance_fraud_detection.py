# -*- coding: utf-8 -*-
"""vehicle-insurance-fraud-detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MqqTjUyQCbPQ3bsdVLgVu4khyevi2MD6
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("carclaims.csv")

df

df.isnull().sum()

df.describe()



df.info()

df.corr()

df.drop(['Make','WeekOfMonth','DayOfWeek','DayOfWeekClaimed','MonthClaimed','WeekOfMonthClaimed','MaritalStatus','PolicyNumber','Days:Policy-Accident','AddressChange-Claim','Year',],axis = 1, inplace = True)

df['AgeOfVehicle'].unique()

df['PastNumberOfClaims'].unique()

df['AgeOfPolicyHolder'].unique()

df['AgeOfVehicle'].unique()

df['VehiclePrice'].unique()

df['NumberOfCars'].unique()

import seaborn as sns

sns.pairplot(df, diag_kind='kde')

sns.barplot(x=df['Fault'],y=df['Age'] , hue = df['Sex'])

sns.catplot(x= 'Fault', y = 'PolicyType', data = df)

plt.figure(figsize=(20,5))
sns.barplot(x=df['Deductible'],y=df['PolicyType'])

plt.figure(figsize=(5,5))
sns.boxplot(x=df['VehicleCategory'],y=df['DriverRating'])

sns.stripplot(x= 'VehicleCategory',y = 'VehiclePrice', data = df)

plt.figure(figsize=(20,10))
sns.stripplot(x= 'PoliceReportFiled',y = 'PolicyType', data = df)

plt.figure(figsize=(20,10))
sns.stripplot(x=df['PolicyType'],y=df['AgeOfPolicyHolder'])

df['PastNumberOfClaims'] = df['PastNumberOfClaims'].map({'none':1,'1':1,'2 to 4':4 , 'more than 4':5})

df['AgeOfVehicle'] = df['AgeOfVehicle'].map({'3 years':3,'6 years':6,'7 years':7,'more than 7':8,'5 years':5,'new': 0, '4 years':4, '2 years':2})

df['AgeOfPolicyHolder'] = df['AgeOfPolicyHolder'].map({'26 to 30':2,'31 to 35':3,'41 to 50':4,
                                                       '51 to 65':6,'21 to 25':1,'36 to 40':5,'16 to 17':0,'over 65':7,'18 to 20':0})

df['NumberOfCars'].unique()

df['FraudFound'] = df['FraudFound'].map({'yes':1,'No':0})

df.drop(['Month'] , axis = 1, inplace = True)

df.drop(['AccidentArea'],axis = 1, inplace = True)

df.drop(['VehicleCategory'],axis = 1, inplace= True)

df1 = pd.get_dummies(df, columns = ['Sex','PoliceReportFiled','Fault','PolicyType','WitnessPresent','AgentType','BasePolicy'],drop_first=True)

df1.info()

df1.corr()

df1['Days:Policy-Claim'].unique()

df1['Days:Policy-Claim'] = df['Days:Policy-Claim'].map({'more than 30':35,'15 to 30':25,'8 to 15':12,'none':0})

df1.drop(['NumberOfSuppliments'],axis = 1, inplace=True)

df1.drop(['VehiclePrice'],axis = 1, inplace=True)

df1.drop(['NumberOfCars'],axis = 1, inplace=True)

df1['FraudFound']=df1['FraudFound'].fillna(value = 1)

from sklearn.model_selection import train_test_split

train = df1.drop('FraudFound',  axis = 1)
test = df1['FraudFound']

x_train, x_test, y_train, y_test = train_test_split(train, test, test_size = 0.19, random_state = 20)

from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression()

logreg.fit(x_train, y_train)

prediction = logreg.predict(x_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test, prediction)

mean = df.loc[:, 'Deductible'].mean() # column average (attribute average / for a feature)
data_item = df.loc[1, 'Deductible'] # specific value for that feature for a certain row
error = (abs(data_item - mean) / mean) * 100
print(error)

# do this for every feature (column) for rows that are fradulent
# put all calculated errors into an array and then retrieve the highest 3 (sort array then get highest)
# so output that the model predicted this row is fraudulent because the values for the 3 features varied significantly from mean

# to test with user input, could use a row from the test data to enter on form and predict (and we can check if it was correct or not using the actual fraud status)
# and if fradulent, use the 3 features that varied from mean in the prompt to get recommendations

